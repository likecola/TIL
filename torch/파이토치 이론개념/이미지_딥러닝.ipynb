{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 합성곱\n",
    "\n",
    "- 작은 필터를 이용해 이미지로부터 특징을 뽑아내는 알고리즘\n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    "### CNN\n",
    "\n",
    "- 합성곱층을 반복적으로 쌓아서 만든 인공 신경망\n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    "### 특징 맵\n",
    "\n",
    "- 합성곱층의 결과\n",
    "\n",
    "- 합성곱층이 특징을 추출한 뒤의 이미지\n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    "### 데이터 증강과 전처리\n",
    "\n",
    "- 더 원활한 학습을 위해 데이터를 수정하는 기법. 데이터 증강은 이미지를 회전시키거나 잘라내는 등, 데이터 하나로 여러가지 형태의 다른 데이터를 만들어 개수를 늘리는 기법\n",
    "\n",
    " \n",
    "\n",
    "**데이터 전처리는 학습에 이용되기 이전에 처리하는 모든 기법을 의미함**\n",
    "\n",
    "- 데이터 증강도 데이터 전처리의 일종\n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    "### 이미지 정규화\n",
    "\n",
    "- 이미지의 픽셀 간 편향을 제거하는 데 사용\n",
    "\n",
    "- 각 채널의 분포가 동일해지므로 학습이 원활하게 이루어짐\n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    "### 패딩\n",
    "\n",
    "- 이미지 외곽을 0으로 채우는 기법으로, 합성곱 전 후 이미지 크기를 같게 만들어 줌\n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    "### 크롭핑\n",
    "\n",
    "- 이미지의 일부분을 잘라내는 것\n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    "### 최대 풀링\n",
    "\n",
    "- 이미지 크기를 줄이는 데 사용하는 기법으로 커널에서 가장 큰 값을 이용\n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    "### 전이 학습\n",
    "\n",
    "- 사전 학습된 모델의 파라미터를 수정해 자신의 데이터셋에 최적화시키는 방법\n",
    "\n",
    "- 학습에 걸리는 시간을 단축함\n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    "### 스트라이드(Stride)\n",
    "\n",
    "- 커널의 이동 거리\n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    "### 커널, 필터\n",
    "\n",
    "- 커널은 이미지로부터 특징을 추출하기 위한 가중치를 행렬로 나타낸 것\n",
    "\n",
    "- 또한 커널의 집합을 필터라고 부릅니다.\n",
    "\n",
    " \n",
    "\n",
    "> 합성곱은 커널을 이미지 안에서 이리저리 움직이며 특징을 추출합니다.\n",
    "\n",
    "따라서 볼 수 잇는 시야는 좁아지는 대신 위치와 무관하게 특징을 잡을 수 있습니다.\n",
    "\n",
    "CNN 커널 크기는 변화가 없어서 이미지 크기와 무관하게 학습해야 하는 가중치 개수가 같습니다.\n",
    "\n",
    "(학습할 가중치가 줄고, 특징의 위치에 대해 자유로워짐)\n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    "### 데이터 증강(data augmentation)\n",
    "\n",
    "- 이미지에 여러 변형을 주어 이미지 개수를 늘리는 기법.\n",
    "\n",
    "- 회전(Rotation), 크기 변경, 밀림(Shearing), 반사(Reflection), 이동(Translation) 등을 사용\n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    "### 정규화(Normalization)\n",
    "\n",
    "- 데이터의 분포를 정규분포의 형태로 바꿔주는 것.\n",
    "\n",
    "- 평균과 표준편차로 설명하는 분포로, 평균이 0, 표준편차가 1인 정규분포를 표준 정규분포라 부른다.\n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    "### 평탄화(Flatten)\n",
    "\n",
    "- MLP층의 입력으로 사용하도록 이미지를 1차원 벡터로 변환하는 층\n",
    "\n",
    "- CNN(Convolutional Neural Network) : 합성곱을 사용하는 신경망\n",
    "\n",
    "- 이미지에 특징이 하나만 있는 게 아니기 때문에 CNN의 한 층에 필터를 여러 개 준비\n",
    "\n",
    " \n",
    "\n",
    "### 합성곱의 계산법\n",
    "\n",
    "1. 원본 이미지 준비\n",
    "\n",
    "2. 합성곱 커널이 CNN에서 특징 추출\n",
    "\n",
    "3. 특징 맵 추출\n",
    "\n",
    " \n",
    "\n",
    "## 자주 사용되는 CNN 모델\n",
    " \n",
    "\n",
    "> VGG\n",
    "\n",
    "- 특징 : 가장 기본이 되는 CNN.\n",
    "\n",
    "- VGG 이전의 CNN은 커널 크기가 커서 학습해야 하는 가중치 수가 많았지만 VGG는 3x3 크기의 커널을 이용해서 가중치 개수를 줄일 수 있습니다.\n",
    "\n",
    " \n",
    "\n",
    "**장점** \n",
    "\n",
    "- VGG는 단순한 구조를 가진 만큼 데이터가 무난한 성능을 발휘합니다.\n",
    "\n",
    "- 구조가 간단하기 때문에 활용하기 간편합니다.\n",
    "\n",
    "- 데이터가 깨끗하지 않을 때도 나쁘지 않은 성능을 보입니다.\n",
    "\n",
    " \n",
    "\n",
    "**단점**\n",
    "\n",
    "- 층이 깊어지면 기울기 소실 문제가 발생합니다.\n",
    "\n",
    "- 학습이 불안정할 때가 있습니다.\n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    "### ResNet\n",
    "\n",
    "- 특징 : 입력 이미지와 특징 맵을 더하는 CNN.\n",
    "\n",
    "층이 깊어질수록 역전파되는 오차가 작아지는 문제를 어느정도 해결함\n",
    "\n",
    "VGG와는 비교도 안되는 깊이를 가졌음\n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    "### Inception\n",
    "\n",
    "- 특징 : 3x3 커널을 여러 번 중첩해 크기가 큰 커널을 근사했음\n",
    "\n",
    "VGG보다 넓은 시야를 가지고 있으며 큰 크기의 커널보다 적은 수의 가중치로 비슷한 효과를 얻음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### ResNet \n",
    "\n",
    "스킵 구조를 이용한 CNN 신경망\n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    "### 기울기 소실(Gradient vanishing)\n",
    "\n",
    "은닉층이 깊어짐에 따라 입력층에 가까운 가중치들의 기울기가 0에 가까워지는 현상을 의미합니다.\n",
    "\n",
    "기울기가 0이 되면 가중치가 더 이상 업데이트되지 않기 때문에 학습이 이루어지지 않습니다.\n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    "### 배치 정규화\n",
    "\n",
    "배치 간의 차이를 정규화 해주므로 더 안정되게 학습할 수 있습니다.\n",
    "\n",
    "모델의 입력으로 들어오는 배치의 값의 분포가 서로 다르면 배치마다 출력 값의 분포 또한 달라지기 때문에\n",
    "\n",
    "학습에 악영향을 미칩니다.\n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    "### nn.Sequential\n",
    "\n",
    "커스터마이징이 불가능하지만 forward() 메서드를 직접 작성할 필요가 없습니다.\n",
    "\n",
    "하지만 신경망 커스터마이징이 되지 않기 때문에 복잡한 신경망에는 nn.Module을 이용합니다.\n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    "### 스킵 커넥션\n",
    "\n",
    "은닉층을 거치지 않은 입력값과 은닉층의 결과를 더하는 구조를 의미합니다.\n",
    "\n",
    "자기 자신을 미분하면 1이 나오기 때문에 신경망의 출력 부분에 입력을 더하는 방식으로 기울기를 최소 1로 확보하는 기법\n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    "### 평균 풀링\n",
    "\n",
    "커널의 평균 값을 이용하는 풀링입니다.\n",
    "\n",
    " \n",
    "\n",
    "### ResNet의 장점과 단점\n",
    "\n",
    " \n",
    "\n",
    "**장점**\n",
    "\n",
    "- 층을 깊게 쌓을 수 있습니다\n",
    "\n",
    "- VGG에 비해 학습이 안정적입니다\n",
    "\n",
    "- 기울기소실 문제를 어느 정도 해결합니다\n",
    "\n",
    " \n",
    "\n",
    "**단점**\n",
    "\n",
    "- 가중치가 늘어나기 때문에 계산량이 많아집니다\n",
    "\n",
    "- VGG에 비해 오버피팅이 일어나기 쉽습니다\n",
    "\n",
    " \n",
    "\n",
    "이미지 분류, 세그멘테이션, 이미지 생성 등 합성곱을 이용하는 모든 곳에서 이용이 가능합니다.\n",
    "\n",
    "스킵 커넥션은 텍스트 처리에도 사용할 수 있습니다.\n",
    "\n",
    "\n",
    "------------------------------\n",
    "\n",
    "\n",
    "### RNN(recurrent neural network)\n",
    "\n",
    "순환하는 인공 신경망\n",
    "\n",
    " \n",
    "\n",
    "- 순서가 있는 데이터에 사용하기 좋다.\n",
    "\n",
    "- 신경망 각 층은 한 시점을 가리키고 있음 \n",
    "\n",
    "- 모든 시점에서의 출력은 다음 시점의 입력값과 합쳐져 가중치가 적용되고,\n",
    "\n",
    "최종 출력값을 출력으로 하며, 출력층 이전의 출력을 은닉 상태라고 부름\n",
    "\n",
    " \n",
    "\n",
    "**장점**\n",
    "\n",
    "- 이전 정보를 현재 시점에서 이용하기 때문에 시간에 대한 정보를 추출할 수 있습니다\n",
    "\n",
    "- 같은 가중치를 반복 사용하기 때문에 가중치 수가 비교적 적음\n",
    "\n",
    " \n",
    "\n",
    "**단점**\n",
    "\n",
    "- 같은 가중치를 여러 번 반복 사용하기 때문에 계산에 시간이 오래걸림\n",
    "\n",
    "- 시계열이 길어질수록 앞의 정보가 점점 흐려짐\n",
    "\n",
    " \n",
    "\n",
    "주가, 날씨, 텍스트 등 순서가 있는 데이터를 다룰 때 용이함"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
