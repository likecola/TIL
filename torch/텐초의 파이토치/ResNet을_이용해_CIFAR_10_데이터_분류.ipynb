{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ResNet의 기본 블록"
      ],
      "metadata": {
        "id": "NOOtDkeBwckT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Zax29QkCwKrs"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "   def __init__(self, in_channels, out_channels, kernel_size=3):\n",
        "       super(BasicBlock, self).__init__()\n",
        "\n",
        "\n",
        "       # ❶ 합성곱층 정의\n",
        "       self.c1 = nn.Conv2d(in_channels, out_channels,\n",
        "                           kernel_size=kernel_size, padding=1)\n",
        "       self.c2 = nn.Conv2d(out_channels, out_channels,\n",
        "                           kernel_size=kernel_size, padding=1)\n",
        "\n",
        "       self.downsample = nn.Conv2d(in_channels, out_channels,\n",
        "                                   kernel_size=1)\n",
        "\n",
        "       # ❷ 배치 정규화층 정의\n",
        "       # 앞에 오는 합성곱층의 출력 채널 만큼의 특징을 가짐\n",
        "       # 즉, num_features안에 합성곱층의 출력 채널 수, out_channels가 들어감\n",
        "\n",
        "       self.bn1 = nn.BatchNorm2d(num_features=out_channels)\n",
        "       self.bn2 = nn.BatchNorm2d(num_features=out_channels)\n",
        "\n",
        "       # BatchNorm2d(features)\n",
        "       # 설명 : 배치 정규화를 실행. features개의 특징에 대해서 실행 (이미지 채널 수만 맞추면 됨)\n",
        "\n",
        "       self.relu = nn.ReLU()\n",
        "   def forward(self, x):\n",
        "       # ❸스킵 커넥션을 위해 초기 입력을 저장\n",
        "       # 입력값과 합성곱층의 출력ㅇㄹ 더해줘야 함\n",
        "       # x_ 변수를 통해서 신경망을 거치지 전의 입력값을 저장\n",
        "       x_ = x\n",
        "\n",
        "       x = self.c1(x)\n",
        "       x = self.bn1(x)\n",
        "       x = self.relu(x)\n",
        "       x = self.c2(x)\n",
        "       x = self.bn2(x)\n",
        "\n",
        "       # ➍합성곱의 결과와 입력의 채널 수를 맞춤\n",
        "       # 입력 이미지에 비해서 특징 맵이 훨씬 더 많은 채널을 가지고 있음\n",
        "       # 따라서 self.downsample로 채널 수를 맞춰줌\n",
        "       x_ = self.downsample(x_)\n",
        "\n",
        "       # ➎합성곱층의 결과와 저장해놨던 입력값을 더해줌\n",
        "       x += x_\n",
        "       x = self.relu(x)\n",
        "\n",
        "       return x"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ResNet 모델 정의하기"
      ],
      "metadata": {
        "id": "uFCX1c7O9Q1h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet(nn.Module):\n",
        "   def __init__(self, num_classes=10):\n",
        "       super(ResNet, self).__init__()\n",
        "\n",
        "\n",
        "       # ❶ 기본 블록\n",
        "       self.b1 = BasicBlock(in_channels=3, out_channels=64)\n",
        "       self.b2 = BasicBlock(in_channels=64, out_channels=128)\n",
        "       self.b3 = BasicBlock(in_channels=128, out_channels=256)\n",
        "\n",
        "\n",
        "       # ❷ 풀링을 최댓값이 아닌 평균값으로\n",
        "       # 커널의 평균값을 이용해 이미지를 풀링하는것을 말함\n",
        "       # AvgPool2d(kernel_size, stride)\n",
        "       # 설명 : 풀링을 커널의 평균 값으로 실행\n",
        "       self.pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "       # ❸ 분류기\n",
        "       self.fc1 = nn.Linear(in_features=4096, out_features=2048)\n",
        "       self.fc2 = nn.Linear(in_features=2048, out_features=512)\n",
        "       self.fc3 = nn.Linear(in_features=512, out_features=num_classes)\n",
        "\n",
        "       self.relu = nn.ReLU()\n",
        "   def forward(self, x):\n",
        "       # ❶ 기본 블록과 풀링층을 통과\n",
        "       x = self.b1(x)\n",
        "       x = self.pool(x)\n",
        "       x = self.b2(x)\n",
        "       x = self.pool(x)\n",
        "       x = self.b3(x)\n",
        "       x = self.pool(x)\n",
        "\n",
        "\n",
        "       # ❷ 분류기의 입력으로 사용하기 위해 flatten\n",
        "       x = torch.flatten(x, start_dim=1)\n",
        "\n",
        "       # ❸ 분류기로 예측값 출력\n",
        "       x = self.fc1(x)\n",
        "       x = self.relu(x)\n",
        "       x = self.fc2(x)\n",
        "       x = self.relu(x)\n",
        "       x = self.fc3(x)\n",
        "\n",
        "       return x"
      ],
      "metadata": {
        "id": "J8YHfDHa9UBk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 전처리 정의"
      ],
      "metadata": {
        "id": "1Xe-UrZP_dFM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm\n",
        "\n",
        "from torchvision.datasets.cifar import CIFAR10\n",
        "from torchvision.transforms import Compose, ToTensor\n",
        "from torchvision.transforms import RandomHorizontalFlip, RandomCrop\n",
        "from torchvision.transforms import Normalize\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "\n",
        "from torch.optim.adam import Adam\n",
        "\n",
        "transforms = Compose([\n",
        "   RandomCrop((32, 32), padding=4), #❶ 랜덤 크롭핑\n",
        "   RandomHorizontalFlip(p=0.5), #❷ 랜덤 y축 대칭\n",
        "   ToTensor(),\n",
        "   Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.247, 0.243, 0.261))\n",
        "])\n"
      ],
      "metadata": {
        "id": "lBTCpqQ1_eGV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 불러오기"
      ],
      "metadata": {
        "id": "VvQIr3wZ_hzk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = CIFAR10(root=\"./\", train=True, download=True, transform=transforms)\n",
        "test_data = CIFAR10(root=\"./\", train=False, download=True, transform=transforms)\n",
        "\n",
        "train_loader = DataLoader(training_data, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5SO2N3k_fmH",
        "outputId": "6b6392d8-abb7-4259-ccb5-8e94ceafbc59"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:03<00:00, 46048839.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./cifar-10-python.tar.gz to ./\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 정의하기"
      ],
      "metadata": {
        "id": "hMPUcSsR_lKv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model = ResNet(num_classes=10)\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Unrr3IM0_jmc",
        "outputId": "0f5afece-d2b1-4535-92c6-8ae55b19f89c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (b1): BasicBlock(\n",
              "    (c1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (c2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (downsample): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (b2): BasicBlock(\n",
              "    (c1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (c2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (downsample): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (b3): BasicBlock(\n",
              "    (c1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (c2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (downsample): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "  (fc1): Linear(in_features=4096, out_features=2048, bias=True)\n",
              "  (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "  (fc3): Linear(in_features=512, out_features=10, bias=True)\n",
              "  (relu): ReLU()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 학습루프 정의"
      ],
      "metadata": {
        "id": "aiH5PXzZ_1ff"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 1e-4\n",
        "optim = Adam(model.parameters(), lr=lr)\n",
        "\n",
        "for epoch in range(30):\n",
        "   iterator = tqdm.tqdm(train_loader)\n",
        "   for data, label in iterator:\n",
        "       # 최적화를 위해 기울기를 초기화\n",
        "       optim.zero_grad()\n",
        "\n",
        "       # 모델의 예측값\n",
        "       preds = model(data.to(device))\n",
        "\n",
        "       # 손실 계산 및 역전파\n",
        "       loss = nn.CrossEntropyLoss()(preds, label.to(device))\n",
        "       loss.backward()\n",
        "       optim.step()\n",
        "\n",
        "       iterator.set_description(f\"epoch:{epoch+1} loss:{loss.item()}\")\n",
        "\n",
        "torch.save(model.state_dict(), \"ResNet.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GzHmxjC_uW3",
        "outputId": "12dde296-e466-41d4-b5b5-216e28876e5c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:1 loss:0.7723923325538635: 100%|██████████| 1563/1563 [00:48<00:00, 32.46it/s]\n",
            "epoch:2 loss:0.8433610796928406: 100%|██████████| 1563/1563 [00:46<00:00, 33.69it/s]\n",
            "epoch:3 loss:0.3760397136211395: 100%|██████████| 1563/1563 [00:46<00:00, 33.65it/s]\n",
            "epoch:4 loss:0.7258491516113281: 100%|██████████| 1563/1563 [00:46<00:00, 33.79it/s]\n",
            "epoch:5 loss:0.9559581279754639: 100%|██████████| 1563/1563 [00:44<00:00, 34.77it/s]\n",
            "epoch:6 loss:0.5560154914855957: 100%|██████████| 1563/1563 [00:45<00:00, 34.16it/s]\n",
            "epoch:7 loss:0.5139148235321045: 100%|██████████| 1563/1563 [00:45<00:00, 34.59it/s]\n",
            "epoch:8 loss:0.5414445996284485: 100%|██████████| 1563/1563 [00:45<00:00, 34.32it/s]\n",
            "epoch:9 loss:0.15274935960769653: 100%|██████████| 1563/1563 [00:45<00:00, 34.71it/s]\n",
            "epoch:10 loss:0.687563419342041: 100%|██████████| 1563/1563 [00:45<00:00, 34.37it/s]\n",
            "epoch:11 loss:0.21277011930942535: 100%|██████████| 1563/1563 [00:45<00:00, 34.67it/s]\n",
            "epoch:12 loss:0.15212741494178772: 100%|██████████| 1563/1563 [00:45<00:00, 34.27it/s]\n",
            "epoch:13 loss:0.18042099475860596: 100%|██████████| 1563/1563 [00:45<00:00, 34.60it/s]\n",
            "epoch:14 loss:0.5527713298797607: 100%|██████████| 1563/1563 [00:45<00:00, 34.36it/s]\n",
            "epoch:15 loss:0.07820907235145569: 100%|██████████| 1563/1563 [00:45<00:00, 34.72it/s]\n",
            "epoch:16 loss:0.3979426920413971: 100%|██████████| 1563/1563 [00:45<00:00, 34.44it/s]\n",
            "epoch:17 loss:0.19343523681163788: 100%|██████████| 1563/1563 [00:44<00:00, 34.83it/s]\n",
            "epoch:18 loss:0.1030922532081604: 100%|██████████| 1563/1563 [00:45<00:00, 34.21it/s]\n",
            "epoch:19 loss:0.044167451560497284: 100%|██████████| 1563/1563 [00:45<00:00, 34.18it/s]\n",
            "epoch:20 loss:0.19611380994319916: 100%|██████████| 1563/1563 [00:46<00:00, 33.92it/s]\n",
            "epoch:21 loss:0.02288960851728916: 100%|██████████| 1563/1563 [00:45<00:00, 34.11it/s]\n",
            "epoch:22 loss:0.07069302350282669: 100%|██████████| 1563/1563 [00:45<00:00, 34.04it/s]\n",
            "epoch:23 loss:0.19656670093536377: 100%|██████████| 1563/1563 [00:46<00:00, 33.95it/s]\n",
            "epoch:24 loss:0.13310301303863525: 100%|██████████| 1563/1563 [00:46<00:00, 33.93it/s]\n",
            "epoch:25 loss:0.06334703415632248: 100%|██████████| 1563/1563 [00:46<00:00, 33.93it/s]\n",
            "epoch:26 loss:0.15043620765209198: 100%|██████████| 1563/1563 [00:45<00:00, 34.07it/s]\n",
            "epoch:27 loss:0.07946781814098358: 100%|██████████| 1563/1563 [00:46<00:00, 33.95it/s]\n",
            "epoch:28 loss:0.008961092680692673: 100%|██████████| 1563/1563 [00:45<00:00, 34.12it/s]\n",
            "epoch:29 loss:0.2184022217988968: 100%|██████████| 1563/1563 [00:45<00:00, 34.21it/s]\n",
            "epoch:30 loss:0.004731699358671904: 100%|██████████| 1563/1563 [00:45<00:00, 34.30it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ResNet 성능 확인해보기"
      ],
      "metadata": {
        "id": "OM62Okrj_9bU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(\"ResNet.pth\", map_location=device))\n",
        "\n",
        "num_corr = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "   for data, label in test_loader:\n",
        "\n",
        "       output = model(data.to(device))\n",
        "       preds = output.data.max(1)[1]\n",
        "       corr = preds.eq(label.to(device).data).sum().item()\n",
        "       num_corr += corr\n",
        "\n",
        "   print(f\"Accuracy:{num_corr/len(test_data)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vR8fq3yX_3Pb",
        "outputId": "a8d8a1ab-bfaf-418b-961c-ffcfda66512b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:0.8848\n"
          ]
        }
      ]
    }
  ]
}