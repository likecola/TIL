{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnwUW-iGK2XO",
        "outputId": "416794ed-b3b3-4971-c3d6-a5402aefa5db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 확인해보기"
      ],
      "metadata": {
        "id": "9FnnF4UnS7CI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "l = []\n",
        "\n",
        "\n",
        "# 한글 텍스트 파일을 읽기 위해 utf-8 인코딩으로 읽어옴\n",
        "with open(\n",
        "    \"/content/CH11.txt\",\n",
        "    'r', encoding=\"utf-8\") as f:\n",
        "   lines = f.read().split(\"\\n\")\n",
        "   for line in lines:\n",
        "       # 특수 문자를 지우고 모든 글자를 소문자로 변경\n",
        "       txt = \"\".join(v for v in line if v not in string.punctuation).lower()\n",
        "       l.append(txt)\n",
        "\n",
        "print(l[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmUb5uQqS65G",
        "outputId": "c9e5d2e4-93bf-40b9-ea81-2eb16c6fa96a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['go\\t가', 'hi\\t안녕', 'run\\t뛰어', 'run\\t뛰어', 'who\\t누구']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BOW를 만드는 함수 정의"
      ],
      "metadata": {
        "id": "mkfkFTduTuof"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from torch.utils.data.dataset import Dataset\n",
        "\n",
        "def get_BOW(corpus):  # 문장들로부터 BOW를 만드는 함수\n",
        "   BOW = {\"<SOS>\":0, \"<EOS>\":1}  # 1. <SOS> 토큰과 <EOS> 토큰을 추가\n",
        "\n",
        "   # 2. 문장 내 단어들을 이용해 BOW를 생성\n",
        "   for line in corpus:\n",
        "       for word in line.split():\n",
        "           if word not in BOW.keys():\n",
        "               BOW[word] = len(BOW.keys())\n",
        "\n",
        "   return BOW"
      ],
      "metadata": {
        "id": "Dg7PdNMXS4Ja"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 학습에 사용할 데이터셋 정의"
      ],
      "metadata": {
        "id": "3CfdQIlfXzdu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Eng2Kor(Dataset):  # 학습에 이용할 데이터셋\n",
        "   def __init__(\n",
        "       self,\n",
        "       pth2txt=\\\n",
        "       \"/content/CH11.txt\"):\n",
        "       self.eng_corpus = []  # 영어 문장이 들어가는 변수\n",
        "       self.kor_corpus = []  # 한글 문장이 들어가는 변수\n",
        "\n",
        "\n",
        "       # ➊ 텍스트 파일을 읽어서 영어 문장과 한글 문장을 저장\n",
        "       with open(pth2txt, 'r', encoding=\"utf-8\") as f:\n",
        "           lines = f.read().split(\"\\n\")\n",
        "           for line in lines:\n",
        "               # 특수 문자와 대문자 제거\n",
        "               txt = \"\".join(\n",
        "                   v for v in line if v not in string.punctuation\n",
        "               ).lower()\n",
        "               engtxt = txt.split(\"\\t\")[0]\n",
        "               kortxt = txt.split(\"\\t\")[1]\n",
        "\n",
        "\n",
        "               # 길이가 10 이하인 문장만을 사용\n",
        "               if len(engtxt.split()) <= 10 and len(kortxt.split()) <= 10:\n",
        "                   self.eng_corpus.append(engtxt)\n",
        "                   self.kor_corpus.append(kortxt)\n",
        "\n",
        "       self.engBOW = get_BOW(self.eng_corpus)  # 영어 BOW\n",
        "       self.korBOW = get_BOW(self.kor_corpus)  # 한글 BOW\n",
        "\n",
        "   # 문장을 단어별로 분리하고 마지막에 <EOS>를 추가\n",
        "   def gen_seq(self, line):\n",
        "       seq = line.split()\n",
        "       seq.append(\"<EOS>\")\n",
        "\n",
        "       return seq\n",
        "   def __len__(self): # ❶ 데이터의 개수를 반환하는 함수\n",
        "       return len(self.eng_corpus)\n",
        "\n",
        "   def __getitem__(self, i): # ❷ 데이터와 정답을 반환하는 함수\n",
        "       # 문자열로 되어 있는 문장을 숫자 표현으로 변경\n",
        "       data = np.array([\n",
        "            self.engBOW[txt] for txt in self.gen_seq(self.eng_corpus[i])])\n",
        "\n",
        "       label = np.array([\n",
        "            self.korBOW[txt] for txt in self.gen_seq(self.kor_corpus[i])])\n",
        "\n",
        "       return data, label"
      ],
      "metadata": {
        "id": "Sg7aTh66XzvM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 학습에 사용할 데이터 로더 정의"
      ],
      "metadata": {
        "id": "2EtgToDQhuWj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loader(dataset):  # 데이터셋의 문장을 한문장씩 불러오기 위한 함수\n",
        "   for i in range(len(dataset)):\n",
        "       data, label = dataset[i]\n",
        "\n",
        "       # ❶ 데이터와 정답을 반환\n",
        "       yield torch.tensor(data), torch.tensor(label)"
      ],
      "metadata": {
        "id": "ZHWEpr60hukd"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 인코더 정의\n",
        "- 임베딩 층과 GRU 층을 쌓는 것"
      ],
      "metadata": {
        "id": "DHkbAdfhisZ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "   def __init__(self, input_size, hidden_size):\n",
        "       super(Encoder, self).__init__()\n",
        "\n",
        "       self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "       self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "       # GRU(input_size, hidden_size, num_layers)\n",
        "       # GRU를 계산합니다. input_size는 입력 벡터의 차원, hidden_size는 은닉 상태의 차원 수,\n",
        "       # num_layers는 쌓아올릴 GRU층의 개수를 정의합니다.\n",
        "\n",
        "   def forward(self, x, h):\n",
        "       # ❶ 배치차원과 시계열 차원 추가\n",
        "       x = self.embedding(x).view(1, 1, -1)\n",
        "       output, hidden = self.gru(x, h)\n",
        "       return output, hidden"
      ],
      "metadata": {
        "id": "nhKC6c7nism8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 디코더 정의\n",
        "1. 현시점의 입력을 임베딩층으로 넣어 밀집 표현으로 바꿔줍니다.\n",
        "2. 임베딩 된 현시점의 입력과 이전 시점의 은닉 상태를 MLP층에 넣어주면 어텐션 가중치를 얻을 수 있습니다.\n",
        "3. 인코더의 출력과 어텐션 가중치를 내적해 인코더 각 시점의 중요도를 계산합니다.\n",
        "4. 임베딩된 현시점의 입력과 합쳐 MLP층에 넣어서 특징을 추출합니다.\n",
        "5. 마지막으로 추출한 특징과 이전 시점의 은닉 상태를 LSTM에 넣어 시계열 정보를 학습합니다."
      ],
      "metadata": {
        "id": "wLqA99UnkQ_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "   def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=11):\n",
        "       super(Decoder, self).__init__()\n",
        "\n",
        "       # 임베딩층 정의\n",
        "       self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "\n",
        "       # 어텐션 가중치를 계산하기 위한 MLP층\n",
        "       self.attention = nn.Linear(hidden_size * 2, max_length)\n",
        "\n",
        "       #특징 추출을 위한 MLP층\n",
        "       self.context = nn.Linear(hidden_size * 2, hidden_size)\n",
        "\n",
        "       # 과적합을 피하기 위한 드롭아웃 층\n",
        "       self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "       # GRU층\n",
        "       self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "       # 단어 분류를 위한 MLP층\n",
        "       self.out = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "       # 활성화 함수\n",
        "       self.relu = nn.ReLU()\n",
        "       self.softmax = nn.LogSoftmax(dim=1)\n",
        "       # LogSoftmax(dim) : 소프트맥스 함수에 로그를 취한 값을 반환합니다.\n",
        "       # dim 차원에 대한 소프트맥스를 계산합니다.\n",
        "\n",
        "   def forward(self, x, h, encoder_outputs):\n",
        "       # ➊입력을 밀집 표현으로\n",
        "       x = self.embedding(x).view(1, 1, -1)\n",
        "       x = self.dropout(x)\n",
        "\n",
        "       # ➋어텐션 가중치 계산\n",
        "       attn_weights = self.softmax(\n",
        "           self.attention(torch.cat((x[0], h[0]), -1)))\n",
        "\n",
        "       # ➌어텐션 가중치와 인코더의 출력을 내적\n",
        "       attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                encoder_outputs.unsqueeze(0))\n",
        "       # bmm(A, B) : A와 B를 내적합니다. A크기가 (B, N , M)이고,\n",
        "       # B크기가 torch(B, M, K)일 때 (B, N, K) 크기의 출력을 반환합니다.\n",
        "\n",
        "       # ➍인코더 각 시점의 중요도와 민집표현을 합쳐\n",
        "       # MLP층으로 특징 추출\n",
        "       output = torch.cat((x[0], attn_applied[0]), 1)\n",
        "       output = self.context(output).unsqueeze(0)\n",
        "       output = self.relu(output)\n",
        "\n",
        "       # ➎GRU층으로 입력\n",
        "       output, hidden = self.gru(output, h)\n",
        "\n",
        "       # ➏예측된 단어 출력\n",
        "       output = self.out(output[0])\n",
        "\n",
        "       return output"
      ],
      "metadata": {
        "id": "ZqoZvQzTknXE"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 학습에 필요한 요소 정의\n",
        "1. 문장을 불러와 한 단어씩 인코더에 입력합니다.\n",
        "2. 각 시점에서의 인코더의 결과를 저장합니다.\n",
        "3. 디코더의 첫 입력으로 <SOS> 토큰을 입력합니다.\n",
        "4. 디코더의 첫 은닉상태로 인코더의 마지막 은닉 상태를 입력합니다.\n",
        "5. 디코더의 예측 단어와 은닉 상태를 다음 시점으로 넘겨줍니다.\n",
        "6. 오차 계산 및 역전파를 진행합니다."
      ],
      "metadata": {
        "id": "L6RMfpjedKfg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import tqdm\n",
        "\n",
        "from torch.optim.adam import Adam\n",
        "\n",
        "\n",
        "# 학습에 사용할 프로세서 정의\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "# 학습에 사용할 데이터셋 정의\n",
        "dataset = Eng2Kor()\n",
        "\n",
        "\n",
        "# 인코더 디코더 정의\n",
        "encoder = Encoder(input_size=len(dataset.engBOW), hidden_size=64).to(device)\n",
        "decoder = Decoder(64, len(dataset.korBOW), dropout_p=0.1).to(device)\n",
        "# 인코더 디코더 학습을 위한 최적화 정의\n",
        "encoder_optimizer = Adam(encoder.parameters(), lr=0.0001)\n",
        "decoder_optimizer = Adam(decoder.parameters(), lr=0.0001)"
      ],
      "metadata": {
        "id": "qei_fOV5dMRi"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 학습 루프 정의"
      ],
      "metadata": {
        "id": "3jVHCoMtd1ga"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(200):\n",
        "   iterator = tqdm.tqdm(loader(dataset), total=len(dataset))\n",
        "   total_loss = 0\n",
        "\n",
        "   for data, label in iterator:\n",
        "       data = torch.tensor(data, dtype=torch.long).to(device)\n",
        "       label = torch.tensor(label, dtype=torch.long).to(device)\n",
        "\n",
        "       # 인코더의 초기 은닉 상태\n",
        "       # 인코더의 모든 시점의 출력을 디코더에서 이용하기 때문\n",
        "       encoder_hidden = torch.zeros(1, 1, 64).to(device)\n",
        "       # 인코더의 모든 시점의 출력을 저장하는 변수\n",
        "       encoder_outputs = torch.zeros(11, 64).to(device)\n",
        "\n",
        "       encoder_optimizer.zero_grad()\n",
        "       decoder_optimizer.zero_grad()\n",
        "\n",
        "       loss = 0\n",
        "       for ei in range(len(data)):\n",
        "           # ➊한 단어씩 인코더에 넣어줌\n",
        "           encoder_output, encoder_hidden = encoder(\n",
        "               data[ei], encoder_hidden)\n",
        "           # ❷인코더의 은닉 상태를 저장\n",
        "           encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "       decoder_input = torch.tensor([[0]]).to(device)\n",
        "\n",
        "       # ❸인코더의 마지막 은닉 상태를 디코더의 초기 은닉 상태로 저장\n",
        "       decoder_hidden = encoder_hidden\n",
        "       use_teacher_forcing = True if random.random() < 0.5 else False  # ❶ 티처 포싱 사용 여부를 랜덤하게 결정\n",
        "\n",
        "       if use_teacher_forcing:\n",
        "           for di in range(len(label)):\n",
        "               decoder_output = decoder(\n",
        "                   decoder_input, decoder_hidden, encoder_outputs)\n",
        "\n",
        "               # 학습이 되지 않은 디코더는 엉뚱한 답을 내놓고 그 답을 토대로 학습이 이루어지기 때문에\n",
        "               # 디코더가 제대로 된 답을 낼 때까지 오랜 시간이 걸림\n",
        "               # 이 시간을 단축하기 위해서 강제적으로 정답을 디코더에 넣는것을 티처 포싱이라고 한다.\n",
        "               # 직접적으로 정답을 다음 시점의 입력으로 넣어줌\n",
        "               target = torch.tensor(label[di], dtype=torch.long).to(device)\n",
        "               target = torch.unsqueeze(target, dim=0).to(device)\n",
        "               loss += nn.CrossEntropyLoss()(decoder_output, target)\n",
        "               decoder_input = target\n",
        "       else:\n",
        "           for di in range(len(label)):\n",
        "               decoder_output = decoder(\n",
        "                   decoder_input, decoder_hidden, encoder_outputs)\n",
        "\n",
        "               # ➊ 가장 높은 확률을 갖는 단어의 인덱스가 topi\n",
        "               topv, topi = decoder_output.topk(1)\n",
        "               decoder_input = topi.squeeze().detach()\n",
        "\n",
        "               # 디코더의 예측값을 다음 시점의 입력으로 넣어줌\n",
        "               target = torch.tensor(label[di], dtype=torch.long).to(device)\n",
        "               target = torch.unsqueeze(target, dim=0).to(device)\n",
        "               loss += nn.CrossEntropyLoss()(decoder_output, target)\n",
        "\n",
        "               if decoder_input.item() == 1:  # <EOS> 토큰을 만나면 중지\n",
        "                   break\n",
        "       # 전체 손실 계산\n",
        "       total_loss += loss.item()/len(dataset)\n",
        "       iterator.set_description(f\"epoch:{epoch+1} loss:{total_loss}\")\n",
        "       loss.backward()\n",
        "\n",
        "       encoder_optimizer.step()\n",
        "       decoder_optimizer.step()\n",
        "\n",
        "torch.save(encoder.state_dict(), \"attn_enc.pth\")\n",
        "torch.save(decoder.state_dict(), \"attn_dec.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_jcy2xvdzy9",
        "outputId": "665e8f20-9231-4017-f967-5b474ecae52c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/3592 [00:00<?, ?it/s]<ipython-input-9-70ecbeb6059f>:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  data = torch.tensor(data, dtype=torch.long).to(device)\n",
            "<ipython-input-9-70ecbeb6059f>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  label = torch.tensor(label, dtype=torch.long).to(device)\n",
            "<ipython-input-9-70ecbeb6059f>:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  target = torch.tensor(label[di], dtype=torch.long).to(device)\n",
            "epoch:1 loss:0.009718331037491626:   0%|          | 1/3592 [00:01<1:55:32,  1.93s/it] <ipython-input-9-70ecbeb6059f>:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  target = torch.tensor(label[di], dtype=torch.long).to(device)\n",
            "epoch:1 loss:22.85723725180317: 100%|██████████| 3592/3592 [00:58<00:00, 61.08it/s]\n",
            "epoch:2 loss:21.867407291397495: 100%|██████████| 3592/3592 [01:13<00:00, 48.80it/s]\n",
            "epoch:3 loss:22.00399469068164: 100%|██████████| 3592/3592 [00:59<00:00, 60.69it/s]\n",
            "epoch:4 loss:21.875975994331: 100%|██████████| 3592/3592 [01:07<00:00, 53.51it/s]\n",
            "epoch:5 loss:21.647712979590157: 100%|██████████| 3592/3592 [01:03<00:00, 56.37it/s]\n",
            "epoch:6 loss:21.21351873648991: 100%|██████████| 3592/3592 [01:05<00:00, 55.06it/s]\n",
            "epoch:7 loss:21.10592573443075: 100%|██████████| 3592/3592 [01:02<00:00, 57.55it/s]\n",
            "epoch:8 loss:21.320843988311804: 100%|██████████| 3592/3592 [01:02<00:00, 57.71it/s]\n",
            "epoch:9 loss:20.756455372396722: 100%|██████████| 3592/3592 [01:00<00:00, 59.45it/s]\n",
            "epoch:10 loss:20.505975897633377: 100%|██████████| 3592/3592 [01:00<00:00, 59.16it/s]\n",
            "epoch:11 loss:20.33105765976724: 100%|██████████| 3592/3592 [00:59<00:00, 59.88it/s]\n",
            "epoch:12 loss:20.25368936237088: 100%|██████████| 3592/3592 [01:01<00:00, 58.80it/s]\n",
            "epoch:13 loss:20.483333948659485: 100%|██████████| 3592/3592 [01:01<00:00, 58.36it/s]\n",
            "epoch:14 loss:19.862900716491136: 100%|██████████| 3592/3592 [01:01<00:00, 58.84it/s]\n",
            "epoch:15 loss:19.937467571820886: 100%|██████████| 3592/3592 [01:02<00:00, 57.90it/s]\n",
            "epoch:16 loss:19.41863625863346: 100%|██████████| 3592/3592 [01:01<00:00, 58.39it/s]\n",
            "epoch:17 loss:19.356993233307957: 100%|██████████| 3592/3592 [01:01<00:00, 58.71it/s]\n",
            "epoch:18 loss:19.178834552687903: 100%|██████████| 3592/3592 [01:02<00:00, 57.61it/s]\n",
            "epoch:19 loss:19.025524168011877: 100%|██████████| 3592/3592 [01:02<00:00, 57.67it/s]\n",
            "epoch:20 loss:18.71972184483882: 100%|██████████| 3592/3592 [01:01<00:00, 58.39it/s]\n",
            "epoch:21 loss:18.5675381604574: 100%|██████████| 3592/3592 [01:02<00:00, 57.17it/s]\n",
            "epoch:22 loss:1.259874680459102:  14%|█▎        | 486/3592 [00:06<00:49, 63.22it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 성능 평가에 필요한 요소 정의\n"
      ],
      "metadata": {
        "id": "P_TZephdfm5D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 인코더 가중치 불러오기\n",
        "encoder.load_state_dict(torch.load(\"attn_enc.pth\", map_location=device))\n",
        "# 디코더 가중치 불러오기\n",
        "decoder.load_state_dict(torch.load(\"attn_dec.pth\", map_location=device))\n",
        "\n",
        "\n",
        "# ❶불러올 영어 문장을 랜덤하게 지정\n",
        "idx = random.randint(0, len(dataset))\n",
        "# 테스트에 사용할 문장\n",
        "input_sentence = dataset.eng_corpus[idx]\n",
        "# 신경망이 번역한 문장\n",
        "pred_sentence = \"\"\n",
        "\n",
        "data, label = dataset[idx]\n",
        "data = torch.tensor(data, dtype=torch.long).to(device)\n",
        "label = torch.tensor(label, dtype=torch.long).to(device)\n",
        "\n",
        "# ➋인코더의 초기 은닉 상태 정의\n",
        "encoder_hidden = torch.zeros(1, 1, 64).to(device)\n",
        "# 인코더 출력을 담기위한 변수\n",
        "encoder_outputs = torch.zeros(11, 64).to(device)"
      ],
      "metadata": {
        "id": "-T3K25fMfZ5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 인코더 동작"
      ],
      "metadata": {
        "id": "uE8IP-78fwF4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for ei in range(len(data)):\n",
        "   # ➊한 단어씩 인코더에 넣어줌\n",
        "   encoder_output, encoder_hidden = encoder(\n",
        "       data[ei], encoder_hidden)\n",
        "\n",
        "   # ➋인코더의 출력을 저장\n",
        "   encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "\n",
        "# ➌디코더의 초기 입력\n",
        "# 0은 <SOS>토큰\n",
        "decoder_input = torch.tensor([[0]]).to(device)\n",
        "\n",
        "# ➍인코더의 마지막 은닉 상태를 디코더의 초기 은닉 상태로\n",
        "decoder_hidden = encoder_hidden"
      ],
      "metadata": {
        "id": "Ig8mPbJCfufU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 디코더 동작"
      ],
      "metadata": {
        "id": "3ONdOERAf7wn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for di in range(11):\n",
        "    # ➊가장 높은 확률을 갖는 단어의 요소를 구함\n",
        "   decoder_output = decoder(\n",
        "                       decoder_input, decoder_hidden, encoder_outputs)\n",
        "   topv, topi = decoder_output.topk(1)\n",
        "   decoder_input = topi.squeeze().detach()\n",
        "\n",
        "   # ➋<EOS> 토큰을 만나면 중지\n",
        "   if decoder_input.item() == 1:\n",
        "       break\n",
        "\n",
        "   # ➌가장 높은 단어를 문자열에 추가\n",
        "   pred_sentence += list(dataset.korBOW.keys())[decoder_input] + \" \"\n",
        "\n",
        "print(input_sentence)  # 영어 문장\n",
        "print(pred_sentence)  # 한글 문장"
      ],
      "metadata": {
        "id": "D_lrddrgf6pn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Zd9S3c43f9Ey"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}