{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBttOtswKQGz"
      },
      "source": [
        "# PyTorch에서 변화도를 0으로 만들기\n",
        "신경망을 구축할 때는 변화도를 0으로 만들어 주는 것이 좋습니다. 기본적으로\n",
        "``.backward()`` 를 호출할 때마다 변화도가 버퍼에 쌓이기 때문입니다. (덮어쓰지 않는다는 의미입니다.)\n",
        "\n",
        "## 개요\n",
        "신경망을 학습시킬 때, 경사 하강법을 거쳐 모델 정확도를 높일 수 있습니다. 경사 하강법은 간단히\n",
        "설명해 모델의 가중치와 편향을 약간씩 수정하면서 손실(또는 오류)를 최소화하는 과정입니다.\n",
        "\n",
        "``torch.Tensor`` 는 PyTorch 의 핵심이 되는 클래스 입니다. 텐서를 생성할 때\n",
        "``.requires_grad`` 속성을 ``True`` 로 설정하면, 텐서에 가해진 모든 연산을 추적합니다.\n",
        "뒤따르는 모든 역전파 단계에서도 마찬가지로, 이 텐서의 변화도는 ``.grad`` 속성에 누적될 것입니다.\n",
        "모든 변화도의 축적 또는 합은 손실 텐서에서 ``.backward()`` 를 호출할 때 계산됩니다.\n",
        "\n",
        "텐서의 변화도를 0으로 만들어 주어야 하는 경우도 있습니다. 예를 들어 학습 과정 반복문을\n",
        "시작할 때, 누적되는 변화도를 정확하게 추적하기 위해서는 변화도를 우선 0으로 만들어 주어야 합니다.\n",
        "이 레시피에서는 PyTorch 라이브러리를 사용하여 변화도를 0으로 만드는 방법을 배워봅니다.\n",
        "PyTorch에 내장된 ``CIFAR10`` 데이터셋에 대하여 신경망을 훈련시키는 과정을 통해 알아봅시다.\n",
        "\n",
        "## 설정\n",
        "이 레시피에는 데이터를 학습시키는 내용이 포함되어 있기 때문에, 실행 가능한 노트북 파일이 있다면\n",
        "런타임을 GPU 또는 TPU로 전환하는 것이 좋습니다. 시작하기에 앞서, ``torch`` 와\n",
        "``torchvision`` 패키지가 없다면 설치합니다.\n",
        "\n",
        "::\n",
        "\n",
        "   pip install torch\n",
        "   pip install torchvision\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOnNh6apKZHi"
      },
      "source": [
        "## 단계(Steps)\n",
        "\n",
        "1단계부터 4단계까지는 학습을 위한 데이터와 신경망을 준비하며, 5단계에서 변화도를 0으로\n",
        "만들어 줍니다. 이미 준비한 데이터와 신경망이 있다면 5단계로 건너뛰어도 좋습니다.\n",
        "\n",
        "1. 데이터를 불러오기 위해 필요한 모든 라이브러리 import 하기\n",
        "2. 데이터셋 불러오고 정규화하기\n",
        "3. 신경망 구축하기\n",
        "4. 손실 함수 정의하기\n",
        "5. 신경망을 학습시킬 때 변화도 0으로 만들기\n",
        "\n",
        "### 1. 데이터를 불러오기 위해 필요한 모든 라이브러리 import 하기\n",
        "\n",
        "이 레시피에서는 데이터셋에 접근하기 위해 ``torch`` 와 ``torchvision`` 을 사용합니다.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Jja9Y7gyKM66"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlQHo_S9Ke_F"
      },
      "source": [
        "### 2. 데이터셋 불러오고 정규화하기\n",
        "\n",
        "PyTorch는 다양한 내장 데이터셋을 제공합니다. PyTorch에서 데이터 불러오기 레시피를 참고해\n",
        "더 많은 정보를 얻을 수 있습니다.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Xol992eKd0v",
        "outputId": "d4f81ac6-a021-4550-f7cb-2bc407ae94f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170498071/170498071 [00:02<00:00, 67491867.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hI01ZCfkKh3K"
      },
      "source": [
        "### 3. 신경망 구축하기\n",
        "\n",
        "컨볼루션 신경망을 정의하겠습니다. 자세한 내용은 신경망 정의하기 레시피를\n",
        "참조해주세요.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_otbI5OZKglK"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a51FlLoiKkE1"
      },
      "source": [
        "### 4. 손실 함수과 옵티마이저 정의하기\n",
        "\n",
        "분류를 위한 Cross-Entropy 손실 함수와 모멘텀을 설정한 SGD 옵티마이저를 사용합니다.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "vTo3gFBKKi93"
      },
      "outputs": [],
      "source": [
        "net = Net()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31iqCKmTKmiL"
      },
      "source": [
        "### 5. 신경망을 학습시키는 동안 변화도를 0으로 만들기\n",
        "\n",
        "이제부터 흥미로운 부분을 살펴보려고 합니다.\n",
        "여기서 할 일은 데이터 이터레이터를 순회하면서, 신경망에 입력을 주고\n",
        "최적화하는 것입니다.\n",
        "\n",
        "데이터의 엔터티 각각의 변화도를 0으로 만들어주는 것에 유의하십시오.\n",
        "신경망을 학습시킬 때 불필요한 정보를 추적하지 않도록 하기 위함입니다.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMeUIjskKpD-",
        "outputId": "a24772d4-9a0d-46bb-831d-88fdb3dd10d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1,  2000] loss: 2.175\n",
            "[1,  4000] loss: 1.841\n",
            "[1,  6000] loss: 1.670\n",
            "[1,  8000] loss: 1.606\n",
            "[1, 10000] loss: 1.510\n",
            "[1, 12000] loss: 1.469\n",
            "[2,  2000] loss: 1.376\n",
            "[2,  4000] loss: 1.388\n",
            "[2,  6000] loss: 1.338\n",
            "[2,  8000] loss: 1.310\n",
            "[2, 10000] loss: 1.309\n",
            "[2, 12000] loss: 1.281\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(2):  # 전체 데이터셋을 여러번 반복하기\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # 입력 받기: 데이터는 [inputs, labels] 형태의 리스트\n",
        "        inputs, labels = data\n",
        "\n",
        "        # 파라미터 변화도를 0으로 만들기\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 순전파 + 역전파 + 최적화\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # 통계 출력\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:    # 미니배치 2000개 마다 출력\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 2000))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3j97gv6_KsA_"
      },
      "source": [
        "``model.zero_grad()`` 를 사용해도 변화도를 0으로 만들 수 있습니다.\n",
        "이는 옵티마이저에 모든 모델 파라미터가 포함되는 한 ``optimizer.zero_grad()`` 를\n",
        "사용하는 것과 동일합니다. 어떤 것을 사용할 것인지 최선의 선택을 하기 바랍니다.\n",
        "\n",
        "축하합니다! 이제 PyTorch에서 변화도를 0으로 만들 수 있습니다.\n",
        "\n",
        "## 더 알아보기\n",
        "\n",
        "다른 레시피를 둘러보고 계속 배워보세요:\n",
        "\n",
        "- :doc:`/recipes/recipes/loading_data_recipe`\n",
        "- :doc:`/recipes/recipes/save_load_across_devices`\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
