{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch를 사용한 훈련\n",
    "아래 동영상을 따라가거나 youtube 링크에서 확인하세요.\n",
    "\n",
    ".. raw:: html\n",
    "\n",
    "   <div style=\"margin-top:10px; margin-bottom:10px;\">\n",
    "     <iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/jF43_wj_DCQ\" frameborder=\"0\" allow=\"accelerometer; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n",
    "   </div>\n",
    "\n",
    "## 소개\n",
    "과거 동영상에서는 다음과 같은 내용을 논의하고 시연했습니다:\n",
    "\n",
    "torch.nn 모듈의 신경망 레이어 및 기능을 사용하여 모델 구축\n",
    "기울기 기반 모델 훈련에 중요한 자동 기울기 계산 메커니즘\n",
    "TensorBoard를 사용하여 훈련 진행 및 기타 활동 시각화\n",
    "이번 동영상에서는 인벤토리에 새로운 도구를 추가할 것입니다:\n",
    "\n",
    "데이터셋 및 데이터로더 추상화에 대해 이해하고, 훈련 루프 중에 모델에 데이터를 공급하는 과정을 살펴봅니다.\n",
    "특정 손실 함수 및 사용 시기에 대해 논의합니다.\n",
    "PyTorch 옵티마이저를 살펴보며, 이는 손실 함수의 결과를 기반으로 모델 가중치를 조절하는 알고리즘을 구현합니다.\n",
    "마지막으로, 이러한 모든 요소를 통합하여 PyTorch 훈련 루프를 실제로 보게 될 것입니다.\n",
    "\n",
    "## 데이터셋 및 데이터로더\n",
    "Dataset 및 DataLoader 클래스는 데이터를 저장소에서 가져와 훈련 루프에 일괄로 노출하는 프로세스를 캡슐화합니다.\n",
    "\n",
    "Dataset은 데이터의 단일 인스턴스에 액세스하고 처리하는 데 책임이 있습니다.\n",
    "\n",
    "DataLoader는 Dataset에서 데이터 인스턴스를 가져와 (자동으로 또는 사용자가 정의한 샘플러와 함께), 이를 일괄로 수집하여 훈련 루프에서 사용할 수 있도록 반환합니다. DataLoader는 데이터의 유형과 상관없이 모든 종류의 데이터셋과 함께 작동합니다.\n",
    "\n",
    "이 자습서에서는 TorchVision에서 제공하는 Fashion-MNIST 데이터셋을 사용합니다. 우리는 torchvision.transforms.Normalize()를 사용하여 이미지 타일 내용의 분포를 제로 중심으로 정규화하고, 훈련 및 검증 데이터 분할을 모두 다운로드합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 60000 instances\n",
      "Validation set has 10000 instances\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# PyTorch TensorBoard support\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Create datasets for training & validation, download if necessary\n",
    "training_set = torchvision.datasets.FashionMNIST('./data', train=True, transform=transform, download=True)\n",
    "validation_set = torchvision.datasets.FashionMNIST('./data', train=False, transform=transform, download=True)\n",
    "\n",
    "# Create data loaders for our datasets; shuffle for training, not for validation\n",
    "training_loader = torch.utils.data.DataLoader(training_set, batch_size=4, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(validation_set, batch_size=4, shuffle=False)\n",
    "\n",
    "# Class labels\n",
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n",
    "\n",
    "# Report split sizes\n",
    "print('Training set has {} instances'.format(len(training_set)))\n",
    "print('Validation set has {} instances'.format(len(validation_set)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "평소와 같이 데이터를 시각화하여 정상 여부를 확인해보겠습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shirt  T-shirt/top  Pullover  Ankle Boot\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Helper function for inline image display\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "dataiter = iter(training_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Create a grid from the images and show them\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "matplotlib_imshow(img_grid, one_channel=True)\n",
    "print('  '.join(classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jupyternotebook error\n",
    "# import os\n",
    "# os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델\n",
    "\n",
    "이 예제에서 사용할 모델은 LeNet-5의 변형입니다. 이전 시리즈의 동영상을 시청한 적이 있다면 이 모델이 익숙할 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# PyTorch models inherit from torch.nn.Module\n",
    "class GarmentClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GarmentClassifier, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = GarmentClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 손실 함수\n",
    "\n",
    "이 예제에서는 교차 엔트로피 손실을 사용합니다. 데모를 위해 더미 출력과 레이블 값을 생성하고, 이들을 손실 함수를 통과시켜 결과를 확인할 것입니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2675, 0.7500, 0.7151, 0.1336, 0.8680, 0.6493, 0.8474, 0.8140, 0.4635,\n",
      "         0.7035],\n",
      "        [0.6280, 0.6337, 0.6495, 0.4431, 0.0508, 0.8207, 0.8367, 0.6804, 0.2518,\n",
      "         0.9701],\n",
      "        [0.1388, 0.9652, 0.4019, 0.0399, 0.1507, 0.2410, 0.4998, 0.6952, 0.3640,\n",
      "         0.7359],\n",
      "        [0.2837, 0.0153, 0.7842, 0.7790, 0.6908, 0.1116, 0.1455, 0.0465, 0.3354,\n",
      "         0.0077]])\n",
      "tensor([1, 5, 3, 7])\n",
      "Total loss for this batch: 2.415609836578369\n"
     ]
    }
   ],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# NB: Loss functions expect data in batches, so we're creating batches of 4\n",
    "# Represents the model's confidence in each of the 10 classes for a given input\n",
    "dummy_outputs = torch.rand(4, 10)\n",
    "# Represents the correct class among the 10 being tested\n",
    "dummy_labels = torch.tensor([1, 5, 3, 7])\n",
    "\n",
    "print(dummy_outputs)\n",
    "print(dummy_labels)\n",
    "\n",
    "loss = loss_fn(dummy_outputs, dummy_labels)\n",
    "print('Total loss for this batch: {}'.format(loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 옵티마이저\n",
    "이 예제에서는 모멘텀을 사용한 단순한 확률적 경사 하강법 (Stochastic Gradient Descent, SGD)_을 사용할 것입니다.\n",
    "\n",
    "이 최적화 기법에 대한 몇 가지 변형을 시도하는 것은 유익할 수 있습니다:\n",
    "\n",
    "학습률은 옵티마이저가 취하는 단계의 크기를 결정합니다. 서로 다른 학습률이 정확도와 수렴 시간에 어떤 영향을 미치는지 확인해 보세요.\n",
    "모멘텀은 최적화기를 여러 단계 동안 가장 강력한 그래디언트 방향으로 밀어냅니다. 이 값을 변경하면 결과에 어떤 영향을 미치는지 살펴보세요.\n",
    "평균 SGD, Adagrad, 또는 Adam과 같은 다양한 최적화 알고리즘을 시도해 보세요. 결과가 어떻게 다르게 나타나는지 확인해보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizers specified in the torch.optim package\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 훈련 루프\n",
    "아래에는 하나의 훈련 에폭을 수행하는 함수가 있습니다. 이 함수는 DataLoader에서 데이터를 열거하며 각 루프의 통과마다 다음을 수행합니다:\n",
    "\n",
    "- DataLoader에서 훈련 데이터의 배치를 가져옵니다.\n",
    "- 옵티마이저의 그래디언트를 0으로 설정합니다.\n",
    "- 추론을 수행합니다. 즉, 입력 배치에 대한 모델의 예측을 얻습니다.\n",
    "- 해당 예측과 데이터셋의 레이블 간의 손실을 계산합니다.\n",
    "- 학습 가중치에 대한 역방향 그래디언트를 계산합니다.\n",
    "- 옵티마이저에게 학습 단계를 수행하도록 지시합니다. 즉, 선택한 최적화 알고리즘에 따라 이 배치에 대한 관측된 그래디언트를 기반으로 모델의 학습 가중치를 조정합니다.\n",
    "- 매 1000 배치마다 손실을 보고합니다.\n",
    "- 마지막 1000 배치에 대한 평균 배치당 손실을 보고합니다. 이 값은 검증 실행과 비교하기 위한 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch_index, tb_writer):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "\n",
    "    # Here, we use enumerate(training_loader) instead of\n",
    "    # iter(training_loader) so that we can track the batch\n",
    "    # index and do some intra-epoch reporting\n",
    "    for i, data in enumerate(training_loader):\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:\n",
    "            last_loss = running_loss / 1000 # loss per batch\n",
    "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
    "            tb_x = epoch_index * len(training_loader) + i + 1\n",
    "            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "            running_loss = 0.\n",
    "\n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 에폭 당 활동\n",
    "에폭 당으로 수행할 몇 가지 작업이 있습니다:\n",
    "\n",
    "훈련에 사용되지 않은 데이터 세트에서 상대적인 손실을 확인하여 검증을 수행하고 이를 보고합니다.\n",
    "모델의 복사본을 저장합니다.\n",
    "여기서 우리는 TensorBoard에서 보고를 수행할 것입니다. 이를 위해서는 명령 줄에서 TensorBoard를 시작하고 다른 브라우저 탭에서 열어야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      "  batch 1000 loss: 1.7203059770613909\n",
      "  batch 2000 loss: 0.8727156349495053\n",
      "  batch 3000 loss: 0.7308477423321456\n",
      "  batch 4000 loss: 0.6411446691597812\n",
      "  batch 5000 loss: 0.6036272091376595\n",
      "  batch 6000 loss: 0.560890505601652\n",
      "  batch 7000 loss: 0.5707613034034148\n",
      "  batch 8000 loss: 0.510251914864406\n",
      "  batch 9000 loss: 0.498426133526722\n",
      "  batch 10000 loss: 0.4857211941695423\n",
      "  batch 11000 loss: 0.4740640135895228\n",
      "  batch 12000 loss: 0.4840794144971296\n",
      "  batch 13000 loss: 0.418788526377175\n",
      "  batch 14000 loss: 0.4320271786942612\n",
      "  batch 15000 loss: 0.4457311078328639\n",
      "LOSS train 0.4457311078328639 valid 0.4384363293647766\n",
      "EPOCH 2:\n",
      "  batch 1000 loss: 0.419783098748303\n",
      "  batch 2000 loss: 0.39336217006485097\n",
      "  batch 3000 loss: 0.400690537323826\n",
      "  batch 4000 loss: 0.3941113630041946\n",
      "  batch 5000 loss: 0.3710038700651494\n",
      "  batch 6000 loss: 0.4130218063859793\n",
      "  batch 7000 loss: 0.3797886263743276\n",
      "  batch 8000 loss: 0.38840005502995334\n",
      "  batch 9000 loss: 0.38306011995195877\n",
      "  batch 10000 loss: 0.34809342174651103\n",
      "  batch 11000 loss: 0.34587898204445083\n",
      "  batch 12000 loss: 0.3489877340550156\n",
      "  batch 13000 loss: 0.352890676015988\n",
      "  batch 14000 loss: 0.3619022444919974\n",
      "  batch 15000 loss: 0.35149403217874353\n",
      "LOSS train 0.35149403217874353 valid 0.36731234192848206\n",
      "EPOCH 3:\n",
      "  batch 1000 loss: 0.35189376898067715\n",
      "  batch 2000 loss: 0.3213222251148036\n",
      "  batch 3000 loss: 0.3270750283987072\n",
      "  batch 4000 loss: 0.32216568334077056\n",
      "  batch 5000 loss: 0.32918083207558085\n",
      "  batch 6000 loss: 0.30956059378598\n",
      "  batch 7000 loss: 0.3535255838566227\n",
      "  batch 8000 loss: 0.33401563743373847\n",
      "  batch 9000 loss: 0.3091961506407024\n",
      "  batch 10000 loss: 0.33780217821791664\n",
      "  batch 11000 loss: 0.33210731636443236\n",
      "  batch 12000 loss: 0.31149291321881173\n",
      "  batch 13000 loss: 0.3319970859996247\n",
      "  batch 14000 loss: 0.31629631744723885\n",
      "  batch 15000 loss: 0.3257514147795737\n",
      "LOSS train 0.3257514147795737 valid 0.3452269732952118\n",
      "EPOCH 4:\n",
      "  batch 1000 loss: 0.31568319369878006\n",
      "  batch 2000 loss: 0.31146136986454803\n",
      "  batch 3000 loss: 0.3112931683108327\n",
      "  batch 4000 loss: 0.28131885963349484\n",
      "  batch 5000 loss: 0.3130940328752331\n",
      "  batch 6000 loss: 0.300541466583094\n",
      "  batch 7000 loss: 0.30048844267634556\n",
      "  batch 8000 loss: 0.3110497599069495\n",
      "  batch 9000 loss: 0.28268248359067366\n",
      "  batch 10000 loss: 0.29015903876611265\n",
      "  batch 11000 loss: 0.2957449068151327\n",
      "  batch 12000 loss: 0.30567537882919715\n",
      "  batch 13000 loss: 0.2958097968954339\n",
      "  batch 14000 loss: 0.300813073722893\n",
      "  batch 15000 loss: 0.31175050505087254\n",
      "LOSS train 0.31175050505087254 valid 0.331280380487442\n",
      "EPOCH 5:\n",
      "  batch 1000 loss: 0.27533834990475586\n",
      "  batch 2000 loss: 0.28638465425136017\n",
      "  batch 3000 loss: 0.28173575105383497\n",
      "  batch 4000 loss: 0.28323127902314765\n",
      "  batch 5000 loss: 0.2947832950870616\n",
      "  batch 6000 loss: 0.27679294558248513\n",
      "  batch 7000 loss: 0.2748620666448605\n",
      "  batch 8000 loss: 0.2955483126360632\n",
      "  batch 9000 loss: 0.2973440778217046\n",
      "  batch 10000 loss: 0.2957908001891701\n",
      "  batch 11000 loss: 0.2730196537148404\n",
      "  batch 12000 loss: 0.256375618231883\n",
      "  batch 13000 loss: 0.28963794766841966\n",
      "  batch 14000 loss: 0.2811461410891425\n",
      "  batch 15000 loss: 0.2937286234700514\n",
      "LOSS train 0.2937286234700514 valid 0.3163261115550995\n"
     ]
    }
   ],
   "source": [
    "# Initializing in a separate cell so we can easily add more epochs to the same run\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter('runs/fashion_trainer_{}'.format(timestamp))\n",
    "epoch_number = 0\n",
    "\n",
    "EPOCHS = 5\n",
    "\n",
    "best_vloss = 1_000_000.\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print('EPOCH {}:'.format(epoch_number + 1))\n",
    "\n",
    "    # Make sure gradient tracking is on, and do a pass over the data\n",
    "    model.train(True)\n",
    "    avg_loss = train_one_epoch(epoch_number, writer)\n",
    "\n",
    "    # We don't need gradients on to do reporting\n",
    "    model.train(False)\n",
    "\n",
    "    running_vloss = 0.0\n",
    "    for i, vdata in enumerate(validation_loader):\n",
    "        vinputs, vlabels = vdata\n",
    "        voutputs = model(vinputs)\n",
    "        vloss = loss_fn(voutputs, vlabels)\n",
    "        running_vloss += vloss\n",
    "\n",
    "    avg_vloss = running_vloss / (i + 1)\n",
    "    print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
    "\n",
    "    # Log the running loss averaged per batch\n",
    "    # for both training and validation\n",
    "    writer.add_scalars('Training vs. Validation Loss',\n",
    "                    { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "                    epoch_number + 1)\n",
    "    writer.flush()\n",
    "\n",
    "    # Track best performance, and save the model's state\n",
    "    if avg_vloss < best_vloss:\n",
    "        best_vloss = avg_vloss\n",
    "        model_path = 'model_{}_{}'.format(timestamp, epoch_number)\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    epoch_number += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델을 저장한 후 불러오려면 다음과 같이 할 수 있습니다:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "saved_model = GarmentClassifier()\n",
    "saved_model.load_state_dict(torch.load(PATH))\n",
    "모델을 로드한 후에는 추가적인 훈련, 추론 또는 분석에 사용할 수 있습니다.\n",
    "\n",
    "단, 모델에 모델 구조에 영향을 주는 생성자 매개변수가 있다면 해당 매개변수를 제공하고 모델을 저장된 상태와 동일하게 구성해야 합니다.\n",
    "\n",
    "## 기타 자료\n",
    "- PyTorch 공식 문서에서 데이터 유틸리티에 관한 내용, 즉 Dataset 및 DataLoader에 대한 정보를 찾을 수 있습니다.\n",
    "- GPU 훈련에 대한 고정 메모리 사용에 대한 노트\n",
    "- TorchVision의 사용 가능한 데이터셋에 대한 문서\n",
    "- TorchText 및 TorchAudio에 대한 데이터셋 문서\n",
    "- PyTorch에서 사용 가능한 손실 함수 문서\n",
    "- torch.optim 패키지 문서, 이는 최적화기 및 학습률 스케줄링과 같은 관련 도구를 포함합니다.\n",
    "- 모델을 저장하고 불러오는 자세한 튜토리얼\n",
    "- pytorch.org의 튜토리얼 섹션에는 다양한 훈련 작업에 대한 자습서가 포함되어 있습니다. 이는 다양한 도메인에서의 - 분류, 생성적 적대 신경망, 강화 학습 등을 다룹니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
